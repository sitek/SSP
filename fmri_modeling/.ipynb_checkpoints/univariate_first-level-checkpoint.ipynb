{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c080696c-3da0-42db-9137-99072ada6cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "\n",
    "from glob import glob\n",
    "from nilearn import plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e15564ab-88b4-4d28-9938-3664b221200d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# ## nilearn modeling: first level\n",
    "# based on: https://nilearn.github.io/auto_examples/04_glm_first_level/plot_bids_features.html#sphx-glr-auto-examples-04-glm-first-level-plot-bids-features-py\n",
    "\n",
    "def prep_models_and_args(subject_id=None, task_id=None, \n",
    "                         fwhm=None, bidsroot=None, \n",
    "                         deriv_dir=None, event_type=None, \n",
    "                         t_r=None, t_acq=None, space_label='T1w'):\n",
    "    from nilearn.glm.first_level import first_level_from_bids\n",
    "    from nilearn.interfaces.fmriprep import load_confounds\n",
    "\n",
    "    data_dir = bidsroot\n",
    "\n",
    "    task_label = task_id\n",
    "    fwhm_sub = fwhm\n",
    "\n",
    "    # correct the fmriprep-given slice reference (middle slice, or 0.5)\n",
    "    # to account for sparse acquisition (silent gap during auditory presentation paradigm)\n",
    "    # fmriprep is explicitly based on slice timings, while nilearn is based on t_r\n",
    "    # and since images are only collected during a portion of the overall t_r (which includes the silent gap),\n",
    "    # we need to account for this\n",
    "    slice_time_ref = 0.5 * t_acq / t_r\n",
    "\n",
    "    print(data_dir, task_label, space_label)\n",
    "\n",
    "    models, models_run_imgs, \\\n",
    "            models_events, \\\n",
    "            models_confounds = first_level_from_bids(data_dir, \n",
    "                                                     task_label, \n",
    "                                                     space_label,\n",
    "                                                     [subject_id],\n",
    "                                                     smoothing_fwhm=fwhm,\n",
    "                                                     derivatives_folder=deriv_dir,\n",
    "                                                     slice_time_ref=slice_time_ref,\n",
    "                                                     minimize_memory=False)\n",
    "\n",
    "\n",
    "    ''' create events '''\n",
    "    # stimulus events\n",
    "    if event_type == 'stimulus':\n",
    "        for sx, sub_events in enumerate(models_events):\n",
    "            print(models[sx].subject_label)\n",
    "            for mx, run_events in enumerate(sub_events):\n",
    "\n",
    "                name_groups = run_events.groupby('trial_type')['trial_type']\n",
    "                suffix = name_groups.cumcount() + 1\n",
    "                repeats = name_groups.transform('size')\n",
    "\n",
    "                run_events['trial_type'] = run_events['trial_type']\n",
    "                run_events['trial_type'] = run_events['trial_type'].str.replace('-','_')\n",
    "\n",
    "        # create stimulus list from updated events.tsv file\n",
    "        stim_list = sorted([s for s in run_events['trial_type'].unique() if str(s) != 'nan'])\n",
    "    \n",
    "    # trial-specific events\n",
    "    if event_type == 'trial':\n",
    "        for sx, sub_events in enumerate(models_events):\n",
    "            print(models[sx].subject_label)\n",
    "            for mx, run_events in enumerate(sub_events):\n",
    "\n",
    "                name_groups = run_events.groupby('trial_type')['trial_type']\n",
    "                suffix = name_groups.cumcount() + 1\n",
    "                repeats = name_groups.transform('size')\n",
    "\n",
    "                run_events['trial_type'] = run_events['trial_type'] + \\\n",
    "                                                    '_trial' + suffix.map(str)\n",
    "                run_events['trial_type'] = run_events['trial_type'].str.replace('-','_')\n",
    "\n",
    "        # create stimulus list from updated events.tsv file\n",
    "        stim_list = sorted([s for s in run_events['trial_type'].unique() if str(s) != 'nan'])\n",
    "\n",
    "    # all sound events\n",
    "    elif event_type == 'sound':\n",
    "        for sx, sub_events in enumerate(models_events):\n",
    "            print(models[sx].subject_label)\n",
    "            for mx, run_events in enumerate(sub_events):\n",
    "                orig_stim_list = sorted([str(s) for s in run_events['trial_type'].unique() if str(s) not in ['nan', 'None']])\n",
    "                #print('original stim list: ', orig_stim_list)\n",
    "\n",
    "                run_events['trial_type'] = run_events.trial_type.str.split('_', expand=True)[0]\n",
    "\n",
    "        # create stimulus list from updated events.tsv file\n",
    "        stim_list = sorted([str(s) for s in run_events['trial_type'].unique() if str(s) not in ['nan', 'None']])\n",
    "        #print('stim list: ', stim_list)\n",
    "\n",
    "    #model_and_args = zip(models, models_run_imgs, models_events, models_confounds)\n",
    "    return stim_list, models, models_run_imgs, models_events, models_confounds, conf_keep_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db69d270-cf4d-495b-92d0-690f88127492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Across-runs GLM\n",
    "def nilearn_glm_across_runs(stim_list, task_label, \n",
    "                            models, models_run_imgs, \n",
    "                            models_events, models_confounds, \n",
    "                            conf_keep_list, space_label):\n",
    "    from nilearn.reporting import make_glm_report\n",
    "    from nilearn.interfaces.bids import save_glm_to_bids\n",
    "    from nilearn.interfaces.fmriprep import load_confounds_strategy\n",
    "    \n",
    "    for midx in range(len(models)):\n",
    "        #for sx, stim in enumerate(stim_list):\n",
    "        \n",
    "        for contrast_label in ['sound', 'response']:\n",
    "            #contrast_desc  = stim\n",
    "\n",
    "\n",
    "            midx = 0\n",
    "            model = models[midx]\n",
    "            imgs = models_run_imgs[midx]\n",
    "            events = models_events[midx]\n",
    "            #confounds = models_confounds[midx]\n",
    "\n",
    "            print(model.subject_label)\n",
    "            print(events[0])\n",
    "\n",
    "            # set limited confounds\n",
    "            print('selecting confounds')\n",
    "            #confounds_ltd = [models_confounds[midx][cx][conf_keep_list] for cx in range(len(models_confounds[midx]))]\n",
    "            confounds_ltd = load_confounds_strategy(img_files=imgs, denoise_strategy='scrubbing')\n",
    "            \n",
    "            #try:\n",
    "            # fit the GLM\n",
    "            print('fitting GLM')\n",
    "            model.fit(imgs, events, confounds_ltd); \n",
    "            print(model)\n",
    "\n",
    "            # compute the contrast of interest\n",
    "            print('computing contrast of interest')\n",
    "            summary_statistics = model.compute_contrast(contrast_label, output_type='all')\n",
    "            zmap = summary_statistics['z_score']\n",
    "            tmap = summary_statistics['stat']\n",
    "            statmap = summary_statistics['effect_size']\n",
    "\n",
    "            ''' ADD BIDS OUTPUTS '''\n",
    "\n",
    "            bidsderiv_sub_dir = os.path.join(bidsroot, 'derivatives', 'nilearn', \n",
    "                                             'bids-deriv_level-1_fwhm-%.02f'%model.smoothing_fwhm, \n",
    "                                             f'sub-{model.subject_label}_space-{space_label}',\n",
    "                                             f'run-all_event-{event_type}')\n",
    "            if not os.path.exists(bidsderiv_sub_dir):\n",
    "                os.makedirs(bidsderiv_sub_dir)\n",
    "\n",
    "            out_prefix = f\"sub-{model.subject_label}_task-{task_label}_fwhm-{model.smoothing_fwhm}\"\n",
    "            save_glm_to_bids(model, \n",
    "                             contrast_label,\n",
    "                             out_dir=bidsderiv_sub_dir,\n",
    "                             prefix=out_prefix,\n",
    "                            )\n",
    "            print(f'Saved model outputs to {bidsderiv_sub_dir}')\n",
    "\n",
    "            #except:\n",
    "            #    print('could not run for ', contrast_label)\n",
    "        return summary_statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54294a23-125c-4544-9c1f-332b3873abdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## plot tsnr\n",
    "def plot_tsnr(bold_files):\n",
    "    from nilearn import image\n",
    "\n",
    "    thresh = 0\n",
    "    fwhm = 5\n",
    "\n",
    "    for fx,filepath in enumerate(bold_files):\n",
    "        tsnr_func = image.math_img('img.mean(axis=3) / img.std(axis=3)', img=filepath)\n",
    "        tsnr_func_smooth = image.smooth_img(tsnr_func, fwhm=5)\n",
    "\n",
    "        display = plotting.plot_stat_map(tsnr_func_smooth, \n",
    "                                        bg_img=t1w_fpath, \n",
    "                                        #title='fMRI single run tSNR map',\n",
    "                                        #cut_coords=[8,50,-20],\n",
    "                                        #threshold=thresh, \n",
    "                                        #cmap='jet'\n",
    "                                        );\n",
    "        display.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be9c16c-089d-4d5f-8f7f-cacea48e1a89",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "838b8d03-b604-4f76-8ca9-48d82b833f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bgfs/bchandrasekaran/krs228/data/SSP/data_bids/derivatives/fmriprep-23.2.1\n"
     ]
    }
   ],
   "source": [
    "task_label = 'badagama'\n",
    "t_acq = 2\n",
    "t_r = 2\n",
    "\n",
    "project_dir = os.path.join('/bgfs/bchandrasekaran/krs228/data/', 'SSP/')\n",
    "bidsroot = os.path.join(project_dir, 'data_bids')\n",
    "deriv_dir = os.path.join(bidsroot, \n",
    "                         'derivatives', \n",
    "                         'fmriprep-23.2.1',\n",
    "                        )\n",
    "print(deriv_dir)\n",
    "nilearn_dir = os.path.join(bidsroot, 'derivatives', 'nilearn')\n",
    "if not os.path.exists(nilearn_dir):\n",
    "        os.makedirs(nilearn_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818abfcb-2347-4ac1-b780-97744b191642",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Univariate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6c5b7f-712b-4d09-8530-fe52eece6a3e",
   "metadata": {},
   "source": [
    "Takes approximately 30 minutes per subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c9059cc-69c2-42eb-a9c6-10aafccff5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "fwhm = 6\n",
    "space_label = 'MNI152NLin2009cAsym'\n",
    "subject_list = ['SSP005', ] # \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34169573-4ce7-4cda-a7b0-203c8e433cdb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running subject  SSP005\n",
      "/bgfs/bchandrasekaran/krs228/data/SSP/data_bids badagama MNI152NLin2009cAsym\n",
      "SSP005\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No events.tsv files found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRunning subject \u001b[39m\u001b[38;5;124m'\u001b[39m, subject_id)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Univariate analysis: MNI space, 3 mm, across-run GLM\u001b[39;00m\n\u001b[1;32m      4\u001b[0m stim_list, models, models_run_imgs, \\\n\u001b[1;32m      5\u001b[0m     models_events, models_confounds, \\\n\u001b[0;32m----> 6\u001b[0m     conf_keep_list \u001b[38;5;241m=\u001b[39m \u001b[43mprep_models_and_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mfwhm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbidsroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mderiv_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msound\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mt_r\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_acq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mspace_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Across-run GLM\u001b[39;00m\n\u001b[1;32m     13\u001b[0m summary_statistics \u001b[38;5;241m=\u001b[39m nilearn_glm_across_runs(stim_list, task_label, \n\u001b[1;32m     14\u001b[0m                                              models, models_run_imgs, \n\u001b[1;32m     15\u001b[0m                                              models_events, models_confounds, \n\u001b[1;32m     16\u001b[0m                                              conf_keep_list, space_label)\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mprep_models_and_args\u001b[0;34m(subject_id, task_id, fwhm, bidsroot, deriv_dir, event_type, t_r, t_acq, space_label)\u001b[0m\n\u001b[1;32m     21\u001b[0m slice_time_ref \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m t_acq \u001b[38;5;241m/\u001b[39m t_r\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(data_dir, task_label, space_label)\n\u001b[1;32m     25\u001b[0m models, models_run_imgs, \\\n\u001b[1;32m     26\u001b[0m         models_events, \\\n\u001b[0;32m---> 27\u001b[0m         models_confounds \u001b[38;5;241m=\u001b[39m \u001b[43mfirst_level_from_bids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mtask_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mspace_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43m[\u001b[49m\u001b[43msubject_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43msmoothing_fwhm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfwhm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mderivatives_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mderiv_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mslice_time_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslice_time_ref\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mminimize_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;03m''' create events '''\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# stimulus events\u001b[39;00m\n",
      "File \u001b[0;32m/bgfs/bchandrasekaran/krs228/software/miniconda3/envs/py3/lib/python3.9/site-packages/nilearn/glm/first_level/first_level.py:1066\u001b[0m, in \u001b[0;36mfirst_level_from_bids\u001b[0;34m(dataset_path, task_label, space_label, sub_labels, img_filters, t_r, slice_time_ref, hrf_model, drift_model, high_pass, drift_order, fir_delays, min_onset, mask_img, target_affine, target_shape, smoothing_fwhm, memory, memory_level, standardize, signal_scaling, noise_model, verbose, n_jobs, minimize_memory, derivatives_folder)\u001b[0m\n\u001b[1;32m   1064\u001b[0m     models_events\u001b[38;5;241m.\u001b[39mappend(events)\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1066\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo events.tsv files found\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;66;03m# Get confounds. If not found it will be assumed there are none.\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;66;03m# If there are confounds, they are assumed to be present for all runs.\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m confounds \u001b[38;5;241m=\u001b[39m get_bids_files(derivatives_path, modality_folder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfunc\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1071\u001b[0m                            file_tag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdesc-confounds*\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1072\u001b[0m                            file_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtsv\u001b[39m\u001b[38;5;124m'\u001b[39m, sub_label\u001b[38;5;241m=\u001b[39msub_label,\n\u001b[1;32m   1073\u001b[0m                            filters\u001b[38;5;241m=\u001b[39mfilters)\n",
      "\u001b[0;31mValueError\u001b[0m: No events.tsv files found"
     ]
    }
   ],
   "source": [
    "for sx, subject_id in enumerate(subject_list):\n",
    "    print('Running subject ', subject_id)\n",
    "    # Univariate analysis: MNI space, 3 mm, across-run GLM\n",
    "    stim_list, models, models_run_imgs, \\\n",
    "        models_events, models_confounds, \\\n",
    "        conf_keep_list = prep_models_and_args(subject_id, task_label, \n",
    "                                             fwhm, bidsroot, \n",
    "                                             deriv_dir, 'sound',\n",
    "                                             t_r, t_acq, \n",
    "                                             space_label)\n",
    "   \n",
    "    # Across-run GLM\n",
    "    summary_statistics = nilearn_glm_across_runs(stim_list, task_label, \n",
    "                                                 models, models_run_imgs, \n",
    "                                                 models_events, models_confounds, \n",
    "                                                 conf_keep_list, space_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b02576-f776-4e71-8646-41cfec91130d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ab40f7-cdc4-40c9-bee7-a11d030aedfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7753dd3c-cac7-45cf-a2f4-7e4db28d9f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ec2826-442e-4985-9044-bfb62c4eb4e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8fd8d947-a5c2-4f5d-98e2-7f41cad1808d",
   "metadata": {},
   "source": [
    "## tSNR estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c96366-c1e6-4b84-bf4b-e0d363b10ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import image\n",
    "space_label = 'MNI152NLin2009cAsym'\n",
    "fwhm = 1.5\n",
    "tsnr_smooth = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a843647-21d5-4561-8a1f-a718b9c324da",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_list_mand = ['FLT01', 'FLT03', 'FLT05', 'FLT07', 'FLT08', 'FLT10', ] # \n",
    "\n",
    "sub_list_nman = ['FLT02', 'FLT04', 'FLT06', 'FLT09', 'FLT11', 'FLT12', 'FLT13', ]\n",
    "\n",
    "sub_list = sub_list_mand + sub_list_nman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54252cc-00c5-4616-9ca9-37800ca79c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_list = ['L-CN', 'L-SOC', 'L-IC', 'L-MGN', 'L-HG', 'L-PP', 'L-PT', 'L-STGp', 'L-STGa', \n",
    "            'R-CN', 'R-SOC', 'R-IC', 'R-MGN', 'R-HG', 'R-PP', 'R-PT', 'R-STGp', 'R-STGa', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236a5a06-0baf-408b-be7c-fb865d7fdf56",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_list_sub = []\n",
    "data_list_roi = []\n",
    "data_list_run = []\n",
    "data_list_tsnr = []\n",
    "\n",
    "for sx, subject_id in enumerate(sub_list):\n",
    "    print('Running subject ', subject_id)\n",
    "    # Univariate analysis: MNI space, 3 mm, across-run GLM\n",
    "    stim_list, models, models_run_imgs, \\\n",
    "        models_events, models_confounds, conf_keep_list = prep_models_and_args(subject_id, task_label, \n",
    "                                                                                 fwhm, bidsroot, \n",
    "                                                                                 deriv_dir, 'sound',\n",
    "                                                                                 t_r, t_acq, space_label)\n",
    "    for mx, mask_descrip in enumerate(roi_list):\n",
    "        #mask_descrip = 'L-STGp'\n",
    "        print(mask_descrip)\n",
    "        masks_dir = os.path.join(nilearn_dir, 'masks', 'sub-%s'%subject_id, 'space-%s'%space_label) #'masks-aparc' # 'masks-dseg' , 'masks-subcort-aud'\n",
    "        mask_fpath = glob(masks_dir + '/*/' + 'sub-{}_space-{}_mask-{}.nii.gz'.format(subject_id, space_label, mask_descrip))[0]\n",
    "\n",
    "        for px, preproc_fpath in enumerate(models_run_imgs[0]):\n",
    "            tsnr_func = image.math_img('img.mean(axis=3) / img.std(axis=3)', img=preproc_fpath);\n",
    "            tsnr_func_smooth = image.smooth_img(tsnr_func, fwhm=tsnr_smooth)\n",
    "\n",
    "            #display = plotting.plot_epi(tsnr_func_smooth, colorbar=True, vmin=10, vmax=100,\n",
    "            #                            title=os.path.basename(preproc_fpath));\n",
    "\n",
    "            fmri_masked, masker = mask_fmri(tsnr_func_smooth, mask_fpath, fwhm)\n",
    "            print(np.mean(fmri_masked))\n",
    "\n",
    "            data_list_sub.append(subject_id)\n",
    "            data_list_roi.append(mask_descrip)\n",
    "            data_list_run.append(px+1)\n",
    "            data_list_tsnr.append(np.mean(fmri_masked))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac380ea-7cd4-4a25-a710-96b643cdd9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data_list_sub))\n",
    "print(len(data_list_roi))\n",
    "print(len(data_list_run))\n",
    "print(len(data_list_tsnr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe902e5-f6ab-4a31-887f-6a6ad46bf8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(data_list_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c29753d-e02a-4492-a494-1e015ffb9891",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(data_list_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc590ec-a2b8-4bc5-8476-c4a6b29637cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b12171-72c0-4ede-a0c1-b26b5fa39b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsnr_df = pd.DataFrame({'sub_id': data_list_sub, 'Region': data_list_roi, 'run': data_list_run, 'tSNR': data_list_tsnr})\n",
    "tsnr_df['hemi'] = tsnr_df.Region.str[0]\n",
    "tsnr_df.Region = tsnr_df.Region.str[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce20e85e-1f3b-45f3-a81a-9315c9f699fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsnr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7a3ade-7f1d-4e6e-aaf0-bb4f685aadd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_tsnr_df = tsnr_df.groupby(['sub_id', 'Region', 'hemi'], as_index=False, sort=False)['tSNR'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2f77cb-2711-4b7e-95c0-375d88f70b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_tsnr_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45207e1b-7ddf-476a-a994-b74ef1a75e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_tsnr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3509a816-e061-43e4-a608-9a7422721b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8,4), dpi=300)\n",
    "sns.swarmplot(data=tsnr_df, x='Region', y='tSNR', hue='hemi')\n",
    "fig.suptitle('temporal SNR by region of interest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbbacb0-605b-41d1-a6f4-54aa9ef4e0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8,4), dpi=300)\n",
    "sns.violinplot(data=mean_tsnr_df, x='Region', y='tSNR', hue='hemi')\n",
    "fig.suptitle('temporal SNR by region of interest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc56071-26f0-4d35-b662-879679f677e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
